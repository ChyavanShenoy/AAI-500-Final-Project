{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error, r2_score\n",
    "import joblib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StationId</th>\n",
       "      <th>Date</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NOx</th>\n",
       "      <th>NH3</th>\n",
       "      <th>CO</th>\n",
       "      <th>SO2</th>\n",
       "      <th>O3</th>\n",
       "      <th>Benzene</th>\n",
       "      <th>Toluene</th>\n",
       "      <th>Xylene</th>\n",
       "      <th>AQI</th>\n",
       "      <th>AQI_Bucket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AP001</td>\n",
       "      <td>2017-11-24</td>\n",
       "      <td>71.36</td>\n",
       "      <td>115.75</td>\n",
       "      <td>1.75</td>\n",
       "      <td>20.65</td>\n",
       "      <td>12.40</td>\n",
       "      <td>12.19</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10.76</td>\n",
       "      <td>109.26</td>\n",
       "      <td>0.17</td>\n",
       "      <td>5.92</td>\n",
       "      <td>0.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AP001</td>\n",
       "      <td>2017-11-25</td>\n",
       "      <td>81.40</td>\n",
       "      <td>124.50</td>\n",
       "      <td>1.44</td>\n",
       "      <td>20.50</td>\n",
       "      <td>12.08</td>\n",
       "      <td>10.72</td>\n",
       "      <td>0.12</td>\n",
       "      <td>15.24</td>\n",
       "      <td>127.09</td>\n",
       "      <td>0.20</td>\n",
       "      <td>6.50</td>\n",
       "      <td>0.06</td>\n",
       "      <td>184.0</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AP001</td>\n",
       "      <td>2017-11-26</td>\n",
       "      <td>78.32</td>\n",
       "      <td>129.06</td>\n",
       "      <td>1.26</td>\n",
       "      <td>26.00</td>\n",
       "      <td>14.85</td>\n",
       "      <td>10.28</td>\n",
       "      <td>0.14</td>\n",
       "      <td>26.96</td>\n",
       "      <td>117.44</td>\n",
       "      <td>0.22</td>\n",
       "      <td>7.95</td>\n",
       "      <td>0.08</td>\n",
       "      <td>197.0</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AP001</td>\n",
       "      <td>2017-11-27</td>\n",
       "      <td>88.76</td>\n",
       "      <td>135.32</td>\n",
       "      <td>6.60</td>\n",
       "      <td>30.85</td>\n",
       "      <td>21.77</td>\n",
       "      <td>12.91</td>\n",
       "      <td>0.11</td>\n",
       "      <td>33.59</td>\n",
       "      <td>111.81</td>\n",
       "      <td>0.29</td>\n",
       "      <td>7.63</td>\n",
       "      <td>0.12</td>\n",
       "      <td>198.0</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AP001</td>\n",
       "      <td>2017-11-28</td>\n",
       "      <td>64.18</td>\n",
       "      <td>104.09</td>\n",
       "      <td>2.56</td>\n",
       "      <td>28.07</td>\n",
       "      <td>17.01</td>\n",
       "      <td>11.42</td>\n",
       "      <td>0.09</td>\n",
       "      <td>19.00</td>\n",
       "      <td>138.18</td>\n",
       "      <td>0.17</td>\n",
       "      <td>5.02</td>\n",
       "      <td>0.07</td>\n",
       "      <td>188.0</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  StationId        Date  PM2.5    PM10    NO    NO2    NOx    NH3    CO  \\\n",
       "0     AP001  2017-11-24  71.36  115.75  1.75  20.65  12.40  12.19  0.10   \n",
       "1     AP001  2017-11-25  81.40  124.50  1.44  20.50  12.08  10.72  0.12   \n",
       "2     AP001  2017-11-26  78.32  129.06  1.26  26.00  14.85  10.28  0.14   \n",
       "3     AP001  2017-11-27  88.76  135.32  6.60  30.85  21.77  12.91  0.11   \n",
       "4     AP001  2017-11-28  64.18  104.09  2.56  28.07  17.01  11.42  0.09   \n",
       "\n",
       "     SO2      O3  Benzene  Toluene  Xylene    AQI AQI_Bucket  \n",
       "0  10.76  109.26     0.17     5.92    0.10    NaN        NaN  \n",
       "1  15.24  127.09     0.20     6.50    0.06  184.0   Moderate  \n",
       "2  26.96  117.44     0.22     7.95    0.08  197.0   Moderate  \n",
       "3  33.59  111.81     0.29     7.63    0.12  198.0   Moderate  \n",
       "4  19.00  138.18     0.17     5.02    0.07  188.0   Moderate  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('station_day.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 108035 entries, 0 to 108034\n",
      "Data columns (total 16 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   StationId   108035 non-null  object \n",
      " 1   Date        108035 non-null  object \n",
      " 2   PM2.5       86410 non-null   float64\n",
      " 3   PM10        65329 non-null   float64\n",
      " 4   NO          90929 non-null   float64\n",
      " 5   NO2         91488 non-null   float64\n",
      " 6   NOx         92535 non-null   float64\n",
      " 7   NH3         59930 non-null   float64\n",
      " 8   CO          95037 non-null   float64\n",
      " 9   SO2         82831 non-null   float64\n",
      " 10  O3          82467 non-null   float64\n",
      " 11  Benzene     76580 non-null   float64\n",
      " 12  Toluene     69333 non-null   float64\n",
      " 13  Xylene      22898 non-null   float64\n",
      " 14  AQI         87025 non-null   float64\n",
      " 15  AQI_Bucket  87025 non-null   object \n",
      "dtypes: float64(13), object(3)\n",
      "memory usage: 13.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_vars = ['PM2.5', 'PM10', 'NO2', 'CO', 'SO2', 'O3']\n",
    "target_classification = 'AQI_Bucket'\n",
    "target_regression = 'AQI'\n",
    "fix_columns = ['PM2.5', 'PM10', 'NO2', 'CO', 'SO2', 'O3', 'AQI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy='mean')\n",
    "df[fix_columns] = imputer.fit_transform(df[fix_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StationId</th>\n",
       "      <th>Date</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NOx</th>\n",
       "      <th>NH3</th>\n",
       "      <th>CO</th>\n",
       "      <th>SO2</th>\n",
       "      <th>O3</th>\n",
       "      <th>Benzene</th>\n",
       "      <th>Toluene</th>\n",
       "      <th>Xylene</th>\n",
       "      <th>AQI</th>\n",
       "      <th>AQI_Bucket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AP001</td>\n",
       "      <td>2017-11-24</td>\n",
       "      <td>71.36</td>\n",
       "      <td>115.75</td>\n",
       "      <td>1.75</td>\n",
       "      <td>20.65</td>\n",
       "      <td>12.40</td>\n",
       "      <td>12.19</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10.76</td>\n",
       "      <td>109.26</td>\n",
       "      <td>0.17</td>\n",
       "      <td>5.92</td>\n",
       "      <td>0.10</td>\n",
       "      <td>179.74929</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AP001</td>\n",
       "      <td>2017-11-25</td>\n",
       "      <td>81.40</td>\n",
       "      <td>124.50</td>\n",
       "      <td>1.44</td>\n",
       "      <td>20.50</td>\n",
       "      <td>12.08</td>\n",
       "      <td>10.72</td>\n",
       "      <td>0.12</td>\n",
       "      <td>15.24</td>\n",
       "      <td>127.09</td>\n",
       "      <td>0.20</td>\n",
       "      <td>6.50</td>\n",
       "      <td>0.06</td>\n",
       "      <td>184.00000</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AP001</td>\n",
       "      <td>2017-11-26</td>\n",
       "      <td>78.32</td>\n",
       "      <td>129.06</td>\n",
       "      <td>1.26</td>\n",
       "      <td>26.00</td>\n",
       "      <td>14.85</td>\n",
       "      <td>10.28</td>\n",
       "      <td>0.14</td>\n",
       "      <td>26.96</td>\n",
       "      <td>117.44</td>\n",
       "      <td>0.22</td>\n",
       "      <td>7.95</td>\n",
       "      <td>0.08</td>\n",
       "      <td>197.00000</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AP001</td>\n",
       "      <td>2017-11-27</td>\n",
       "      <td>88.76</td>\n",
       "      <td>135.32</td>\n",
       "      <td>6.60</td>\n",
       "      <td>30.85</td>\n",
       "      <td>21.77</td>\n",
       "      <td>12.91</td>\n",
       "      <td>0.11</td>\n",
       "      <td>33.59</td>\n",
       "      <td>111.81</td>\n",
       "      <td>0.29</td>\n",
       "      <td>7.63</td>\n",
       "      <td>0.12</td>\n",
       "      <td>198.00000</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AP001</td>\n",
       "      <td>2017-11-28</td>\n",
       "      <td>64.18</td>\n",
       "      <td>104.09</td>\n",
       "      <td>2.56</td>\n",
       "      <td>28.07</td>\n",
       "      <td>17.01</td>\n",
       "      <td>11.42</td>\n",
       "      <td>0.09</td>\n",
       "      <td>19.00</td>\n",
       "      <td>138.18</td>\n",
       "      <td>0.17</td>\n",
       "      <td>5.02</td>\n",
       "      <td>0.07</td>\n",
       "      <td>188.00000</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  StationId        Date  PM2.5    PM10    NO    NO2    NOx    NH3    CO  \\\n",
       "0     AP001  2017-11-24  71.36  115.75  1.75  20.65  12.40  12.19  0.10   \n",
       "1     AP001  2017-11-25  81.40  124.50  1.44  20.50  12.08  10.72  0.12   \n",
       "2     AP001  2017-11-26  78.32  129.06  1.26  26.00  14.85  10.28  0.14   \n",
       "3     AP001  2017-11-27  88.76  135.32  6.60  30.85  21.77  12.91  0.11   \n",
       "4     AP001  2017-11-28  64.18  104.09  2.56  28.07  17.01  11.42  0.09   \n",
       "\n",
       "     SO2      O3  Benzene  Toluene  Xylene        AQI AQI_Bucket  \n",
       "0  10.76  109.26     0.17     5.92    0.10  179.74929        NaN  \n",
       "1  15.24  127.09     0.20     6.50    0.06  184.00000   Moderate  \n",
       "2  26.96  117.44     0.22     7.95    0.08  197.00000   Moderate  \n",
       "3  33.59  111.81     0.29     7.63    0.12  198.00000   Moderate  \n",
       "4  19.00  138.18     0.17     5.02    0.07  188.00000   Moderate  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df[target_classification] = label_encoder.fit_transform(df[target_classification])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StationId</th>\n",
       "      <th>Date</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NOx</th>\n",
       "      <th>NH3</th>\n",
       "      <th>CO</th>\n",
       "      <th>SO2</th>\n",
       "      <th>O3</th>\n",
       "      <th>Benzene</th>\n",
       "      <th>Toluene</th>\n",
       "      <th>Xylene</th>\n",
       "      <th>AQI</th>\n",
       "      <th>AQI_Bucket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AP001</td>\n",
       "      <td>2017-11-24</td>\n",
       "      <td>71.36</td>\n",
       "      <td>115.75</td>\n",
       "      <td>1.75</td>\n",
       "      <td>20.65</td>\n",
       "      <td>12.40</td>\n",
       "      <td>12.19</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10.76</td>\n",
       "      <td>109.26</td>\n",
       "      <td>0.17</td>\n",
       "      <td>5.92</td>\n",
       "      <td>0.10</td>\n",
       "      <td>179.74929</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AP001</td>\n",
       "      <td>2017-11-25</td>\n",
       "      <td>81.40</td>\n",
       "      <td>124.50</td>\n",
       "      <td>1.44</td>\n",
       "      <td>20.50</td>\n",
       "      <td>12.08</td>\n",
       "      <td>10.72</td>\n",
       "      <td>0.12</td>\n",
       "      <td>15.24</td>\n",
       "      <td>127.09</td>\n",
       "      <td>0.20</td>\n",
       "      <td>6.50</td>\n",
       "      <td>0.06</td>\n",
       "      <td>184.00000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AP001</td>\n",
       "      <td>2017-11-26</td>\n",
       "      <td>78.32</td>\n",
       "      <td>129.06</td>\n",
       "      <td>1.26</td>\n",
       "      <td>26.00</td>\n",
       "      <td>14.85</td>\n",
       "      <td>10.28</td>\n",
       "      <td>0.14</td>\n",
       "      <td>26.96</td>\n",
       "      <td>117.44</td>\n",
       "      <td>0.22</td>\n",
       "      <td>7.95</td>\n",
       "      <td>0.08</td>\n",
       "      <td>197.00000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AP001</td>\n",
       "      <td>2017-11-27</td>\n",
       "      <td>88.76</td>\n",
       "      <td>135.32</td>\n",
       "      <td>6.60</td>\n",
       "      <td>30.85</td>\n",
       "      <td>21.77</td>\n",
       "      <td>12.91</td>\n",
       "      <td>0.11</td>\n",
       "      <td>33.59</td>\n",
       "      <td>111.81</td>\n",
       "      <td>0.29</td>\n",
       "      <td>7.63</td>\n",
       "      <td>0.12</td>\n",
       "      <td>198.00000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AP001</td>\n",
       "      <td>2017-11-28</td>\n",
       "      <td>64.18</td>\n",
       "      <td>104.09</td>\n",
       "      <td>2.56</td>\n",
       "      <td>28.07</td>\n",
       "      <td>17.01</td>\n",
       "      <td>11.42</td>\n",
       "      <td>0.09</td>\n",
       "      <td>19.00</td>\n",
       "      <td>138.18</td>\n",
       "      <td>0.17</td>\n",
       "      <td>5.02</td>\n",
       "      <td>0.07</td>\n",
       "      <td>188.00000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  StationId        Date  PM2.5    PM10    NO    NO2    NOx    NH3    CO  \\\n",
       "0     AP001  2017-11-24  71.36  115.75  1.75  20.65  12.40  12.19  0.10   \n",
       "1     AP001  2017-11-25  81.40  124.50  1.44  20.50  12.08  10.72  0.12   \n",
       "2     AP001  2017-11-26  78.32  129.06  1.26  26.00  14.85  10.28  0.14   \n",
       "3     AP001  2017-11-27  88.76  135.32  6.60  30.85  21.77  12.91  0.11   \n",
       "4     AP001  2017-11-28  64.18  104.09  2.56  28.07  17.01  11.42  0.09   \n",
       "\n",
       "     SO2      O3  Benzene  Toluene  Xylene        AQI  AQI_Bucket  \n",
       "0  10.76  109.26     0.17     5.92    0.10  179.74929           6  \n",
       "1  15.24  127.09     0.20     6.50    0.06  184.00000           1  \n",
       "2  26.96  117.44     0.22     7.95    0.08  197.00000           1  \n",
       "3  33.59  111.81     0.29     7.63    0.12  198.00000           1  \n",
       "4  19.00  138.18     0.17     5.02    0.07  188.00000           1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 108035 entries, 0 to 108034\n",
      "Data columns (total 16 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   StationId   108035 non-null  object \n",
      " 1   Date        108035 non-null  object \n",
      " 2   PM2.5       108035 non-null  float64\n",
      " 3   PM10        108035 non-null  float64\n",
      " 4   NO          90929 non-null   float64\n",
      " 5   NO2         108035 non-null  float64\n",
      " 6   NOx         92535 non-null   float64\n",
      " 7   NH3         59930 non-null   float64\n",
      " 8   CO          108035 non-null  float64\n",
      " 9   SO2         108035 non-null  float64\n",
      " 10  O3          108035 non-null  float64\n",
      " 11  Benzene     76580 non-null   float64\n",
      " 12  Toluene     69333 non-null   float64\n",
      " 13  Xylene      22898 non-null   float64\n",
      " 14  AQI         108035 non-null  float64\n",
      " 15  AQI_Bucket  108035 non-null  int64  \n",
      "dtypes: float64(13), int64(1), object(2)\n",
      "memory usage: 13.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[learning_vars]\n",
    "\n",
    "y_class = df[target_classification]\n",
    "y_reg = df[target_regression]\n",
    "\n",
    "y_dual = df[[target_classification, target_regression]]\n",
    "\n",
    "X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(X, y_class, test_size=0.2, random_state=42)\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X, y_reg, test_size=0.2, random_state=42)\n",
    "X_train_dual, X_test_dual, y_train_dual, y_test_dual = train_test_split(X, y_dual, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_class = scaler.fit_transform(X_train_class)\n",
    "X_test_class = scaler.transform(X_test_class)\n",
    "X_train_reg = scaler.fit_transform(X_train_reg)\n",
    "X_test_reg = scaler.transform(X_test_reg)\n",
    "X_train_dual = scaler.fit_transform(X_train_dual)\n",
    "X_test_dual = scaler.transform(X_test_dual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_class_tensor = torch.tensor(X_train_class, dtype=torch.float32)\n",
    "y_train_class_tensor = torch.tensor(y_train_class.values, dtype=torch.long)\n",
    "X_train_reg_tensor = torch.tensor(X_train_reg, dtype=torch.float32)\n",
    "y_train_reg_tensor = torch.tensor(y_train_reg.values, dtype=torch.float32)\n",
    "X_train_dual_tensor = torch.tensor(X_train_dual, dtype=torch.float32)\n",
    "y_train_dual_tensor = torch.tensor(y_train_dual.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.28      0.41      1098\n",
      "           1       0.66      0.60      0.63      5867\n",
      "           2       0.58      0.29      0.39      2338\n",
      "           3       0.61      0.71      0.66      4697\n",
      "           4       0.83      0.67      0.74      1051\n",
      "           5       0.72      0.76      0.74      2391\n",
      "           6       0.61      0.85      0.71      4165\n",
      "\n",
      "    accuracy                           0.65     21607\n",
      "   macro avg       0.68      0.60      0.61     21607\n",
      "weighted avg       0.65      0.65      0.63     21607\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logistic_model = LogisticRegression(max_iter=200)\n",
    "logistic_model.fit(X_train_class, y_train_class)\n",
    "y_pred_class_logistic = logistic_model.predict(X_test_class)\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_test_class, y_pred_class_logistic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.69      0.73      1098\n",
      "           1       0.78      0.81      0.79      5867\n",
      "           2       0.66      0.63      0.65      2338\n",
      "           3       0.76      0.83      0.79      4697\n",
      "           4       0.83      0.82      0.82      1051\n",
      "           5       0.77      0.79      0.78      2391\n",
      "           6       0.97      0.86      0.91      4165\n",
      "\n",
      "    accuracy                           0.80     21607\n",
      "   macro avg       0.79      0.78      0.78     21607\n",
      "weighted avg       0.80      0.80      0.80     21607\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_classifier = RandomForestClassifier(n_estimators=50, random_state=0)\n",
    "rf_classifier.fit(X_train_class, y_train_class)\n",
    "y_pred_class_rf = rf_classifier.predict(X_test_class)\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_test_class, y_pred_class_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regression Metrics:\n",
      "MSE: 1656.723178675042\n",
      "R2 Score: 0.8824298696150571\n"
     ]
    }
   ],
   "source": [
    "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_regressor.fit(X_train_reg, y_train_reg)\n",
    "y_pred_reg_rf = rf_regressor.predict(X_test_reg)\n",
    "print(\"Random Forest Regression Metrics:\")\n",
    "print(\"MSE:\", mean_squared_error(y_test_reg, y_pred_reg_rf))\n",
    "print(\"R2 Score:\", r2_score(y_test_reg, y_pred_reg_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifierTorch(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(MLPClassifierTorch, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 200)\n",
    "        self.fc2 = nn.Linear(200, 100)\n",
    "        self.fc3 = nn.Linear(100, 50)\n",
    "        self.fc4 = nn.Linear(50, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.softmax(self.fc4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X_train_class.shape[1]\n",
    "output_size = len(label_encoder.classes_)\n",
    "mlp_classifier_torch = MLPClassifierTorch(input_size, output_size)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(mlp_classifier_torch.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 1.9424\n",
      "Epoch [20/100], Loss: 1.9397\n",
      "Epoch [30/100], Loss: 1.9368\n",
      "Epoch [40/100], Loss: 1.9335\n",
      "Epoch [50/100], Loss: 1.9295\n",
      "Epoch [60/100], Loss: 1.9246\n",
      "Epoch [70/100], Loss: 1.9185\n",
      "Epoch [80/100], Loss: 1.9111\n",
      "Epoch [90/100], Loss: 1.9021\n",
      "Epoch [100/100], Loss: 1.8916\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    outputs = mlp_classifier_torch(X_train_class_tensor)\n",
    "    loss = criterion(outputs, y_train_class_tensor)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Classification Report:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [21607, 86428]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m y_pred_class_mlp \u001b[38;5;241m=\u001b[39m mlp_classifier_torch(X_train_class_tensor)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMLP Classification Report:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_class_mlp\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Desktop/UniProjectGithub/AAI-500-Final-Project/.venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/UniProjectGithub/AAI-500-Final-Project/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:2626\u001b[0m, in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2491\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m   2492\u001b[0m     {\n\u001b[1;32m   2493\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2517\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2518\u001b[0m ):\n\u001b[1;32m   2519\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a text report showing the main classification metrics.\u001b[39;00m\n\u001b[1;32m   2520\u001b[0m \n\u001b[1;32m   2521\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <classification_report>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2623\u001b[0m \u001b[38;5;124;03m    <BLANKLINE>\u001b[39;00m\n\u001b[1;32m   2624\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2626\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2628\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2629\u001b[0m         labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\n",
      "File \u001b[0;32m~/Desktop/UniProjectGithub/AAI-500-Final-Project/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:103\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03mThis converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03my_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    102\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred)\n\u001b[0;32m--> 103\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    105\u001b[0m type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/UniProjectGithub/AAI-500-Final-Project/.venv/lib/python3.12/site-packages/sklearn/utils/validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    460\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [21607, 86428]"
     ]
    }
   ],
   "source": [
    "# mlp_classifier = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=300, random_state=42)\n",
    "# mlp_classifier.fit(X_train_class, y_train_class)\n",
    "# y_pred_class_mlp = mlp_classifier_torch.predict(X_test_class)\n",
    "y_pred_class_mlp = mlp_classifier_torch(X_train_class_tensor)\n",
    "print(\"MLP Classification Report:\")\n",
    "print(classification_report(y_test_class, y_pred_class_mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Regression Metrics:\n",
      "MSE: 1699.397994992062\n",
      "R2 Score: 0.879401431440758\n"
     ]
    }
   ],
   "source": [
    "mlp_regressor = MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=300, random_state=42)\n",
    "mlp_regressor.fit(X_train_reg, y_train_reg)\n",
    "y_pred_reg_mlp = mlp_regressor.predict(X_test_reg)\n",
    "print(\"MLP Regression Metrics:\")\n",
    "print(\"MSE:\", mean_squared_error(y_test_reg, y_pred_reg_mlp))\n",
    "print(\"R2 Score:\", r2_score(y_test_reg, y_pred_reg_mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Dual Prediction Metrics:\n",
      "MSE (AQI_Bucket): 1.987573014570189\n",
      "MSE (AQI): 1690.2473674677003\n"
     ]
    }
   ],
   "source": [
    "y_dual = df[[target_classification, target_regression]]\n",
    "X_train_dual, X_test_dual, y_train_dual, y_test_dual = train_test_split(X, y_dual, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_dual = scaler.fit_transform(X_train_dual)\n",
    "X_test_dual = scaler.transform(X_test_dual)\n",
    "\n",
    "mlp_dual = MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=300, random_state=42)\n",
    "mlp_dual.fit(X_train_dual, y_train_dual)\n",
    "y_pred_dual = mlp_dual.predict(X_test_dual)\n",
    "\n",
    "print(\"MLP Dual Prediction Metrics:\")\n",
    "print(\"MSE (AQI_Bucket):\", mean_squared_error(y_test_dual[target_classification], y_pred_dual[:, 0]))\n",
    "print(\"MSE (AQI):\", mean_squared_error(y_test_dual[target_regression], y_pred_dual[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_encoder.pkl']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(logistic_model, 'logistic_model.pkl')\n",
    "joblib.dump(rf_classifier, 'rf_classifier.pkl')\n",
    "joblib.dump(rf_regressor, 'rf_regressor.pkl')\n",
    "joblib.dump(mlp_classifier, 'mlp_classifier.pkl')\n",
    "joblib.dump(mlp_regressor, 'mlp_regressor.pkl')\n",
    "joblib.dump(mlp_dual, 'mlp_dual.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "joblib.dump(label_encoder, 'label_encoder.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_models(x_new_test):\n",
    "    # Load models and scaler\n",
    "    logistic_model = joblib.load('logistic_model.pkl')\n",
    "    rf_classifier = joblib.load('rf_classifier.pkl')\n",
    "    rf_regressor = joblib.load('rf_regressor.pkl')\n",
    "    mlp_classifier = joblib.load('mlp_classifier.pkl')\n",
    "    mlp_regressor = joblib.load('mlp_regressor.pkl')\n",
    "    mlp_dual = joblib.load('mlp_dual.pkl')\n",
    "    scaler = joblib.load('scaler.pkl')\n",
    "    label_encoder = joblib.load('label_encoder.pkl')\n",
    "\n",
    "    # Scale the custom data\n",
    "    x_new_test_scaled = scaler.transform(x_new_test)\n",
    "\n",
    "    # Make predictions\n",
    "    logistic_pred = logistic_model.predict(x_new_test_scaled)\n",
    "    logistic_label = label_encoder.inverse_transform(logistic_pred)\n",
    "\n",
    "    rf_class_pred = rf_classifier.predict(x_new_test_scaled)\n",
    "    rf_class_label = label_encoder.inverse_transform(rf_class_pred)\n",
    "\n",
    "    rf_reg_pred = rf_regressor.predict(x_new_test_scaled)\n",
    "\n",
    "    mlp_class_pred = mlp_classifier.predict(x_new_test_scaled)\n",
    "    mlp_class_label = label_encoder.inverse_transform(mlp_class_pred)\n",
    "\n",
    "    mlp_reg_pred = mlp_regressor.predict(x_new_test_scaled)\n",
    "\n",
    "    mlp_dual_pred = mlp_dual.predict(x_new_test_scaled)\n",
    "    mlp_dual_class_label = label_encoder.inverse_transform(mlp_dual_pred[:, 0].astype(int))\n",
    "    mlp_dual_reg_pred = mlp_dual_pred[:, 1]\n",
    "\n",
    "    # Print predictions\n",
    "    print(\"Logistic Regression Prediction:\", logistic_label)\n",
    "    print(\"Random Forest Classification Prediction:\", rf_class_label)\n",
    "    print(\"Random Forest Regression Prediction:\", rf_reg_pred)\n",
    "    print(\"MLP Classification Prediction:\", mlp_class_label)\n",
    "    print(\"MLP Regression Prediction:\", mlp_reg_pred)\n",
    "    print(\"MLP Dual Prediction - Classification Label:\", mlp_dual_class_label)\n",
    "    print(\"MLP Dual Prediction - Regression Value:\", mlp_dual_reg_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_test_data = {\n",
    "    'PM2.5': [21],\n",
    "    'PM10': [19],\n",
    "    'NO2': [8],\n",
    "    'CO': [1],\n",
    "    'SO2': [1],\n",
    "    'O3': [10]\n",
    "}\n",
    "x_new_test = pd.DataFrame(custom_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Prediction: ['Satisfactory']\n",
      "Random Forest Classification Prediction: ['Satisfactory']\n",
      "Random Forest Regression Prediction: [80.76991485]\n",
      "MLP Classification Prediction: ['Satisfactory']\n",
      "MLP Regression Prediction: [66.30558873]\n",
      "MLP Dual Prediction - Classification Label: ['Moderate']\n",
      "MLP Dual Prediction - Regression Value: [64.0536822]\n"
     ]
    }
   ],
   "source": [
    "predict_models(x_new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
